{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# For converting text into vecors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "\n",
    "# Getting a simple regression model to train \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hughes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")  \n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  sentiment\n",
      "0  Stuning even for the non-gamer: This sound tra...          1\n",
      "1  The best soundtrack ever to anything.: I'm rea...          1\n",
      "2  Amazing!: This soundtrack is my favorite music...          1\n",
      "3  Excellent Soundtrack: I truly like this soundt...          1\n",
      "4  Remember, Pull Your Jaw Off The Floor After He...          1\n"
     ]
    }
   ],
   "source": [
    "# Load first 50,000 samples to save memory\n",
    "def load_data(filename, num_samples=50000): \n",
    "    reviews = []\n",
    "    sentiments = []\n",
    "\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= num_samples:    # Changed from 'line >= num_samples'\n",
    "                break\n",
    "            parts = line.strip().split(\" \", 1) # Split at the first Space\n",
    "            if len(parts) == 2:\n",
    "                label, text = parts\n",
    "                sentiment = 1 if label == \"__label__2\" else 0\n",
    "                reviews.append(text)\n",
    "                sentiments.append(sentiment)    # Fixed typo in 'append'\n",
    "\n",
    "    return pd.DataFrame({\"reviews\": reviews, \"sentiment\": sentiments})\n",
    "\n",
    "# Load both train and test data\n",
    "df_train = load_data(\"/Users/hughes/Downloads/amazon_data/train.ft.txt\")\n",
    "df_test = load_data(\"/Users/hughes/Downloads/amazon_data/test.ft.txt\")\n",
    "\n",
    "# Show the first few rows\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  \\\n",
      "0  Stuning even for the non-gamer: This sound tra...   \n",
      "1  The best soundtrack ever to anything.: I'm rea...   \n",
      "2  Amazing!: This soundtrack is my favorite music...   \n",
      "3  Excellent Soundtrack: I truly like this soundt...   \n",
      "4  Remember, Pull Your Jaw Off The Floor After He...   \n",
      "\n",
      "                                       clean_reviews  \n",
      "0  stuning even nongamer sound track beautiful pa...  \n",
      "1  best soundtrack ever anything im reading lot r...  \n",
      "2  amazing soundtrack favorite music time hands i...  \n",
      "3  excellent soundtrack truly like soundtrack enj...  \n",
      "4  remember pull jaw floor hearing youve played g...  \n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "     text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text.lower())  # Remove special characters & convert to lowercase\n",
    "     words = text.split()\n",
    "     words = [word for word in words if word not in stop_words]\n",
    "     return \" \".join(words)\n",
    "\n",
    "# Apply cleaning function to both train and test data\n",
    "df_train[\"clean_reviews\"] = df_train[\"reviews\"].apply(clean_text)\n",
    "df_test[\"clean_reviews\"] = df_test[\"reviews\"].apply(clean_text)\n",
    "\n",
    "y_train = df_train[\"sentiment\"]  # Target labels for training\n",
    "y_test = df_test[\"sentiment\"]    # Target labels for testing\n",
    "\n",
    "\n",
    "# Show first few rows after cleaning\n",
    "print(df_train[[\"reviews\", \"clean_reviews\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Cleaned Text to Numbers\n",
    "# Since Ml models only understand numbers, we convert words into TF-Idf vectors.\n",
    "vectorizer = TfidfVectorizer(max_features= 5000) # Convert words to numerical vectors  \n",
    "X_train = vectorizer.fit_transform(df_train[\"clean_reviews\"])\n",
    "X_test = vectorizer.transform(df_test[\"clean_reviews\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "# Train a Simple ML Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Check Accuracy  \n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment: 50.75%\n",
      "Negative Sentiment: 49.25%\n",
      "Neutral Sentiment: -0.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sentiment percentages for positive, negative, and neutral reviews\n",
    "positive_reviews = df_test[df_test['sentiment'] == 1]\n",
    "negative_reviews = df_test[df_test['sentiment'] == 0]\n",
    "\n",
    "positive_percentage = len(positive_reviews) / len(df_test) * 100\n",
    "negative_percentage = len(negative_reviews) / len(df_test) * 100\n",
    "neutral_percentage = 100 - positive_percentage - negative_percentage\n",
    "\n",
    "\n",
    "print(f\"Positive Sentiment: {positive_percentage:.2f}%\")\n",
    "print(f\"Negative Sentiment: {negative_percentage:.2f}%\")\n",
    "print(f\"Neutral Sentiment: {neutral_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Key Themes/Words in Reviews: ['book', 'one', 'great', 'good', 'like', 'movie', 'would', 'read', 'time', 'get']\n"
     ]
    }
   ],
   "source": [
    "# Extraction of Key Themes\n",
    "# Vectorize the cleaned reviews using TF-IDF\n",
    "vectorized = TfidfVectorizer(max_features=10) #Top 10 words\n",
    "X = vectorized.fit_transform(df_train[\"clean_reviews\"])\n",
    "\n",
    "# Get Feature names (words)\n",
    "words = np.array(vectorized.get_feature_names_out())\n",
    "\n",
    "# Get the highest TF-IDF values (scores)\n",
    "tfidf_scores = np.array(X.sum(axis=0)).flatten()\n",
    "\n",
    "# Get the top words based on TF-IDF score\n",
    "top_words = [words[i] for i in tfidf_scores.argsort()[-10:][::-1]]  # Top 10 words\n",
    "top_scores = sorted(tfidf_scores, reverse=True)[:10]\n",
    "\n",
    "print(f\"Top 10 Key Themes/Words in Reviews: {top_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "          \n",
      "ðŸ“Š SENTIMENT ANALYSIS REPORT ðŸ“Š          \n",
      "==================================================\n",
      "\n",
      "ðŸ“ˆ SENTIMENT DISTRIBUTION\n",
      "------------------------------\n",
      "ðŸ“— Positive Reviews:  50.75%\n",
      "ðŸ“• Negative Reviews:  49.25%\n",
      "ðŸ“˜ Neutral Reviews:    0.00%\n",
      "\n",
      "ðŸ”‘ TOP 10 KEY THEMES\n",
      "------------------------------\n",
      " 1. book            | Score: 10209.0684\n",
      " 2. one             | Score: 7793.6119\n",
      " 3. great           | Score: 6704.3770\n",
      " 4. good            | Score: 6239.9403\n",
      " 5. like            | Score: 6222.4218\n",
      " 6. movie           | Score: 5559.9327\n",
      " 7. would           | Score: 5261.8505\n",
      " 8. read            | Score: 5098.5915\n",
      " 9. time            | Score: 4576.2034\n",
      "10. get             | Score: 4486.4289\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_report(df_train, df_test):\n",
    "    # Sentiment Percentages\n",
    "    positive_reviews = df_test[df_test['sentiment'] == 1]\n",
    "    negative_reviews = df_test[df_test['sentiment'] == 0]\n",
    "\n",
    "    positive_percentage = len(positive_reviews) / len(df_test) * 100\n",
    "    negative_percentage = len(negative_reviews) / len(df_test) * 100\n",
    "    neutral_percentage = 100 - (positive_percentage + negative_percentage)\n",
    "\n",
    "    # Key Themes Extraction\n",
    "    vectorizer = TfidfVectorizer(max_features=10)\n",
    "    X = vectorizer.fit_transform(df_train[\"clean_reviews\"])\n",
    "    words = np.array(vectorizer.get_feature_names_out())\n",
    "    tfidf_scores = np.array(X.sum(axis=0)).flatten()\n",
    "\n",
    "    top_words = [words[i] for i in tfidf_scores.argsort()[-10:][::-1]]\n",
    "    top_scores = sorted(tfidf_scores, reverse=True)[:10]\n",
    "\n",
    "    # Enhanced Report Output\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nðŸ“Š SENTIMENT ANALYSIS REPORT ðŸ“Š\".center(50))\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"ðŸ“ˆ SENTIMENT DISTRIBUTION\")\n",
    "    print(\"-\"*30)\n",
    "    print(f\"ðŸ“— Positive Reviews: {positive_percentage:>6.2f}%\")\n",
    "    print(f\"ðŸ“• Negative Reviews: {negative_percentage:>6.2f}%\")\n",
    "    print(f\"ðŸ“˜ Neutral Reviews:  {neutral_percentage:>6.2f}%\")\n",
    "    \n",
    "    print(\"\\nðŸ”‘ TOP 10 KEY THEMES\")\n",
    "    print(\"-\"*30)\n",
    "    for i, (word, score) in enumerate(zip(top_words, top_scores), 1):\n",
    "        print(f\"{i:2d}. {word:<15} | Score: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Generate the report\n",
    "sentiment_analysis_report(df_train, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
